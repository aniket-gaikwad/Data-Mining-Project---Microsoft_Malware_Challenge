#!/usr/bin/python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.decomposition import PCA
import math
import numpy as np
import math
import sys

#train=[[1,2,2,1],[2,1,1,1],[1,1,1,1],[1,1,2,1],[1,1,1,2]]
#label=[1,1,2,1,2]
#test=[[1,1,2,1],[1,1,1,1]]

train=[]
label=[]
test=[]
actualLabel=[]
predicted={}
#Local machine 
trainFile='features.csv'
testFile='test.csv'
#Big red II
#trainFile='/N/dc2/scratch/anikgaik/dm/features.csv'
#testFile='/N/dc2/scratch/anikgaik/dm/test.csv'

#trainFile='/N/dc2/scratch/hydargah/dm/featureFiles/2gramTrain.features'
#testFile='/N/dc2/scratch/hydargah/dm/featureFiles/2gramTest.features'
newTrainFile='train_PCA.csv'
newTestFile='test_PCA.csv'
newTrainLabel='LABELS.csv'
newTestFileList='TESTFILENAMES.csv'


testFileList=[]
l=0
newTrain=[]
newTest=[]
explained_train_var_ratio=[]
explained_test_var_ratio=[]

def CALL_PCA():
	global l,newTrain,newTest,explained_train_var_ratio,explained_test_var_ratio,label,testFileList
	f=open(trainFile)
	f.readline()
	for line in iter(f):
		token=line.split(',')
		l=len(token)
		train.append(token[1:len(token)-1])
		label.append(token[-1].replace('\n',''))
	f.close()

	f=open(testFile)
	f.readline()
	for line in iter(f):
		token=line.split(',')
		testFileList.append(token[0])	
		test.append(token[1:])
		#actualLabel.append(token[-1].replace('\n',''))
	f.close()
	#print("Train : ")
	#print(train)
	#print("Test : ")
	#print(test)
	print("******* PCA o train data ************")
	X=np.array(train)
	pca=PCA(n_components=10)
	newTrain=pca.fit_transform(X)
	print("***** Transormed train data *****")
	print(newTrain)
	print("***** Explained Variance by data ******")
	explained_train_var_ratio=pca.explained_variance_ratio_
	print(explained_train_var_ratio)

	print("******* PCA on test data ************")
	X=np.array(test)
	pca=PCA(n_components=10)
	newTest=pca.fit_transform(X)
	print("***** Transormed test data *****")
	print(newTest)
	print("***** Explained Variance by data ******")
	explained_test_var_ratio=pca.explained_variance_ratio_
	print(explained_train_var_ratio)
	#explained_variance=[]
	#explained_variance.extend(pca.explained_variance_ratio_)
	#for var in pca.explained_variance_ratio_:
		#if var > 0.8:
			#print(x_new[explained_variance.index(var)])
	#print(x_new)



def main():
	#with open(trainFile) as f:
	#	firstLine=f.readline()
	#	for line in f:
	#		token=line.split(',')
	#		train.append(token[1:len(token)-1])
	#		label.append(token[-1].replace('\n',''))

	#with open(testFile) as f:
	#	firstLine=f.readline()
	#	for line in f:
	#		token=line.split(',')
	#		testFileList.append(token[0])	
	#		test.append(token[1:len(token)-1])
	#		actualLabel.append(token[-1].replace('\n',''))

	#for l in train:
		#print(l)

	#print("Label : ")
	#print(label)		

	#CALL_PCA()
	

	f=open(newTrainFile,'r')
	for line in f:
		line=line.split(',')
		newTrain.append(line)
	f.close()	

	f=open(newTestFile,'r')
	for line in f:
		line=line.split(',')
		newTest.append(line)
	f.close()
	
	f=open(newTrainLabel,'r')
	for line in f:
		line=line.split(',')
		label.append(line)
	f.close()	
	
	f=open(newTestFileList,'r')
	for line in f:
		line=line.replace('\n','')
		print(line)
		testFileList.append(line)
	f.close()

	h=GradientBoostingClassifier(n_estimators=100)
	h.fit(newTrain,label)
	#predicted_probs = [[testFileList[index],index + 1, x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],max(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8])] for index, x in enumerate(h.predict_proba(test))]
	predicted_probs = [[testFileList[index],x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],max(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8])] for index, x in enumerate(h.predict_proba(newTest))]

	print("predicted_probs :")
	print(predicted_probs)

	#for probList in predicted_probs:
	#	if probList[1] in predicted:
	#		print("ERROR")
	#	else:
	#		predicted[probList[1]]=getPredictionCLass(probList)#probList.index(probList[-1])

	 
	with open('GRADIENT_Tprediction.csv', 'w') as the_file:
		for prediction in predicted_probs:		
			the_file.write(str(prediction[:len(prediction)-1]))
			the_file.write('\n')
	data=""		
	with open('GRADIENT_Tprediction.csv','r') as the_file:
		for line in the_file:
			data+=line.replace('[','').replace(']','').replace("'",'').replace('.asm','')

	with open('GRADIENT_prediction.csv', 'w') as the_file:
		the_file.write(data)

	#print("actualLabel : ")
	#print(actualLabel)
	#print("predicted : ")
	#print(predicted)

	#wt=calculateWeight(actualLabel,predicted)
	#print("Weight : "+str(wt))

def calculateWeight(actualLabel,predicted):
	count=0
	superCount=0
	for label in predicted:
		superCount+=1
		#print(str(predicted[label])+","+actualLabel[label-1])
		if str(predicted[label])==actualLabel[label-1] :
			count+=1
	#print(count)
	return(float(count)/superCount)

def getPredictionCLass(probList):
	for entry in probList[1:]:
		if(entry>=0.7):
			#print("Hit")
			return probList.index(entry)
	return probList.index(probList[-1])

if __name__=="__main__":
	orig_stdout=sys.stdout
	f=file('LOG_GRADIENTBOOSTING.txt','w')
	sys.stdout=f
	main()
